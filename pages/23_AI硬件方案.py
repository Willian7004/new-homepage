import streamlit as st
st.set_page_config(layout="wide")
st.title("硬件方案")
st.subheader("1.GPU方案", divider=True)
st.write("英伟达的GPU在AI领域比较常用，在数据中心中H100以及下一代的B100等型号比较常用。不过在数据中心领域也有计算卡形式的AMD MI300、昇腾910b和使用SRAM的有带宽优势的Groq、Wafer Scale ENgine等竞品。在消费级中AMD的显卡低精度算力较低，比较少用，而英特尔的显卡算力性价比有优势。")
st.write("在适合个人用户的产品中，英伟达Tesla P40等二手计算卡因为价格低、显存大曾经在一般用户中有较高热度，但由于旧产品没有提高低精度算力的Tensor Core而开始使用Tensor Core的V100价格较高，个人用户大多使用消费级显卡运行算力需求较高的AI模型。")
st.write("一些英伟达消费级显卡由于有相同核心的大显存专业卡，可以通过改用单颗容量较大的显存或在PCB板背面加焊显存以搭载更多显存。其中最常用的是通过改焊单颗2g显存的2080ti 22g，虽然作为矿卡可靠性一般，但由于大显存且性价比高，有不少人使用。而无需改显存的大显存方案需要RTX3090。")
st.write("随着模型小型化和显存优化的发展，16g或12g显存的显卡足以运行phi4模型以及在Hunyuan Video生成低帧率视频，Flux.1以及Fish Speech需要的显存更少，并且有一些性价比优于2080ti 22g的方案。16g显存的英特尔a770算力接近2080ti、价格低不少并且没有矿卡风险。12g显存的2060 12g降低了入门门槛。")
st.write("目前的消费级GPU并没有表现出较明显的对AI应用优化的趋势，在下一代产品中有一部分有改善。英特尔A580将推出24g版本，应该会成为第一款3000以内的全新24g显卡，并且可能在较短时间降价到2500以内，算力也相当于4070。AMD下一代核显会使用2倍890m的规模和内存通道，从而实现算力和带宽的提升。")

st.subheader("2.CPU方案", divider=True)
st.write("同代的同级别产品中，CPU的AI性能一般比GPU低不少。在二手产品中CPU在溢价较少的情况下仍需要更高成本达到与GPU方案相同的算力，但由于CPU方案扩展内存的成本较低，在运行大参数量LLM特别是MoE以及运行没有显存优化的视频模型时性价比较高。")
st.write("低于主流价位的方案主要是英特尔至强E5v3系列，由于支持ddr3内存，可以降低内存扩展成本，双路大约120g内存带宽。具体选择上，偏向性能的话双路2698bv3刚好64核，在Windows上可以避免分组。如果希望提高算力性价比，2666v3等型号有优势。")
st.write("主流价位以上的方案主要是AMD EPYC 7002系列，使用ddr4内存，单路或双路均为8通道大约400g内存带宽。其中性能最高的方案是使用双路共128核的7742，性能相当于RTX3090。接近主流价位的方案是单路7742（性能相当于2070Super）。")

st.subheader("3.移动设备和嵌入式设备", divider=True)
st.write("移动设备和嵌入式设备主要使用较小的端侧模型，不过可以选择优先内存较大的版本以部署phi4等性能较高的模型。近年来不少手机和嵌入式处理器搭载了NPU，在AI绘画等算力要求较高的应用中有比较好的表现。")

st.subheader("4.高带宽迷你主机", divider=True)
st.write("这类产品使用高带宽内存来运行AI应用，结合专用处理器实现体积和功耗优势，性价比通常不如CPU方案。通用产品包括Mac Studio和AMD AI Max系列，并且有对应的笔记本电脑产品。一些计算卡企业也开发了对AI应用优化的专用产品，包括Project Digits（英伟达架构）和香橙派AI Studio Pro（昇腾架构）")

st.subheader("5.优势方案的变化", divider=True)
st.write("AI绘画/视频方面，在可以拉高分辨率的CogVideoX5b Fun出现之前，使用Comfyui的显存优化时6g显存够用了，CogVideoX5b Fun以及后来的CogVideoX1.5缺少显存优化，Hunyuan Video参数量更大，需要的显存大一些，但总体偏向GPU方案。Cosmos模型再次做到了8g显存能生成3秒，并且能实现704p分辨率和较好的运动效果，比较实用。")
st.write("LLM方面，Gemma2出现之前旗舰模型参数量较大，内存较大的非GPU方案仍值得考虑，但Gemma2 27b接近旗舰性能，Qwen2.5 32b正式达到旗舰性能，后面接近旗舰性能的Phi4只有14b参数量，适合单卡部署，又考虑到推理模型对生成速度要求较高，GPU方案就再次获得优势了。")
st.write("至于未来的优势方案。目前受需求到产品的滞后性、端侧AI应用实际需求不大以及需要兼顾其它应用等因素影响，当前的AI硬件不是最佳形态。后续如果AI应用需求扩大且游戏等应用能改用纯AI形式，在GPU/SoC中的低精度张量部分会使用更大面积以提高算力，显存容量和带宽也有望进一步提高。")

st.subheader("6.当前的硬件的问题", divider=True)
st.write("当前的消费级硬件大多没有充分考虑AI用途，向量计算单元面积较小或没有向大显存、高带宽方向发展。出现这一现象一方面原因是企业注重利润以及偏向数据中心市场，另一方面原因是大部分用户且具有较高性能要求的有需求的端侧AI应用较少。")

